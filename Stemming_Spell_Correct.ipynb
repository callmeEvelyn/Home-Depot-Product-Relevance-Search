{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flower\n",
      "playing\n"
     ]
    }
   ],
   "source": [
    "# Data_Preprocessing: Lemmatizer \n",
    "# Lemmatizer e.g. flowers -> flower, cats --> cat\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def lammertizer(word):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return lemmatizer.lemmatize(word)\n",
    "\n",
    "# input: text\n",
    "# def lammertizer(text):\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     return [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
    "\n",
    "\n",
    "\n",
    "# print(lemmatizer.lemmatize(\"cats\"))\n",
    "print(lammertizer(\"flowers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data_Preprocessing: Stemming\n",
    "# Stemming: reducing a word into its stem, i.e. its root form.\n",
    "# e.g. waited, waits, waiting -> wait\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "def stemming(text):\n",
    "    ps = PorterStemmer()\n",
    "    stems = [ps.stem(token) for token in text.split(\" \")]\n",
    "    return stems\n",
    "\n",
    "# words_bag = [\"python\",\"player\",\"playing\",\"talked\",\"efficiently\"]\n",
    "# Test\n",
    "example_words_bag = \"python playing talked efficiently\"\n",
    "print(stemming(example_words_bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a sample test dataset\n",
    "sample = df_all.iloc[:5, :]\n",
    "# print(sample)\n",
    "# print(type(sample))\n",
    "sample.to_csv('test_sample.csv', encoding='utf-8')\n",
    "\n",
    "# Get a sample test dataframe: df_sample\n",
    "df_sample = pd.read_csv('test_sample2.csv')\n",
    "print(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Spell Correction: \n",
    "### Step1: using the Google dict to correct wrong spelling\n",
    "\n",
    "from google_dict import *\n",
    "def google_dict_map(df):\n",
    "    df['search_term']=df['search_term'].map(lambda x: google_dict[x] if x in google_dict.keys() else x)   \n",
    "    return df\n",
    "\n",
    "# Test sample dataset to test google_dict_map() method, correct wrong spell\n",
    "google_dict_map(df_sample)\n",
    "# Save spell correct data to csv file\n",
    "df_sample.to_csv('test_sample_correct.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whats   up (hello 1)\n"
     ]
    }
   ],
   "source": [
    "##### AUTOMATIC SPELL CHECKER ##################################\n",
    "import re\n",
    "\n",
    "def simple_parser(s):\n",
    "    s = s.replace(\"-\",\" \")\n",
    "    s = s.replace(\"+\",\" \")\n",
    "    s = re.sub(r'&amp;', '&', s)\n",
    "    s = re.sub(r'&nbsp;', '', s) \n",
    "#     s = re.sub(r'&#39;', '', s) # remove apostrophe (')\n",
    "    s = s.replace(\"'\", \"\")\n",
    "    s = re.sub(r'(?<=[a-zA-Z])\\/(?=[a-zA-Z])', ' ', s)\n",
    "    s = re.sub(r'(?<=\\))(?=[a-zA-Z0-9])', ' ', s) # add space between parentheses and letters\n",
    "    s = re.sub(r'(?<=[a-zA-Z0-9])(?=\\()', ' ', s)  # add space between parentheses and letters\n",
    "    s = re.sub(r'(?<=[a-zA-Z0-9][\\.\\,])(?=[a-zA-Z])', ' ', s) # add space after dot or colon between letters\n",
    "    return s\n",
    "\n",
    "# Test\n",
    "try_str = simple_parser(\"what's + up(hello+1)\") # whats   up (hello 1)\n",
    "print(try_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
